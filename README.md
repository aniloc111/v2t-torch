# v2t-torch

Attention-Based video2text in Torch

This repository holds many Torch implementations of the seq2seq architecture for video captioning. The original paper, titled Sequence to Sequence -- Video to Text, can be found [here](https://arxiv.org/pdf/1505.00487.pdf). The best model uses an attention mechanism before the captioning layer. 

